◆何がしたいか
・技術習得に集中したい
・トレンドに敏感になりたい

◆解決したい問題
・技術習得の効率化
			・お試し記事の選別が面倒
			・読むべき記事を忘れてしまう、取得漏れしてしまう
・記事ネタ収集の効率化
			・IT系ニュースサイトの巡回
			・取捨選択の自動化（→適量だけを目に入れたい）
			（・興味のない情報が排除されてしまう）
			（・無駄な情報の排除 / 興味のある情報に絞る）

◆解決方法
・pythonでdbとの連携を可能にして、slackbot、scrapingの幅を広げる
・scrapingで必要な情報のみ取得
・slackでの通知で定点観測の習慣化
・探したい情報をいつでも取れるように

◆アルゴ
・基本はすべての記事URLを保存
・欲しい条件設定
			→条件に一致する記事を通知
・ランダム記事
			→毎日数件必ず読む用に通知

--------------------------------------------------
◆知りたい情報

◆ニュース内の情報
・タイトル
（・見出し文章）
・記事属性
			・<<種別1>>タグ / カテゴリ
			・<<種別2>>トレンド / コラム / 新技術おためし / 問題解決
・記事リンク
=====
サイト依存
・人気度
・<<種別3>>自由欄

◆ニュース外の情報
・取得日
・掲載日
・取得元サイト
・取得元元サイト

◆WH
・いつ			：毎日朝夕
・どれくらいの			：読める分だけ
・どうやって			：slack＋検索用アプリ
・だれに			：基本自分向け
--------------------------------------------------
◆機能案
・上記内容保存（どこまで保存するか検討） // TODO 20190528
・<<種別1>>付与
・<<種別2>>判定 / 付与
・slack通知
・選択機能（<<種別1>>, <<種別2>>, 条件設定）
・通知機能（限定通知 / 検索）

--------------------------------------------------
◆テーブル定義
→設計書に移動
C:\work\IDE\Git\20_work\git\NewsScraping\設計書\NewsScrapingforSlack.xlsx

--------------------------------------------------
【検討事項】
001.同じ記事を何回も保存・通知してしまう件
　→サイトurlの一致で重複を確認
　→primary keyに取得日を追加して、重複を認識する
　→[記事付与情報テーブル]の主キーは記事IDのみで管理し、
　　記事に更新があるごとに"記事更新後既読フラグ"をリセットする
　
　案①重複を判定しない（テーブル内の記事重複を許容する）
　案②<<URL>>重複で弾き、二度と表示しない
　案③<<URL>>重複を認識し、上書きする
　案④<<URL>>重複を認識し、取得日を分けて保存することで、更新扱いにする
　※<<URL>>はサイトによって異なる
◆検討結果（20190531）
　↓
　案④は取得日以外のカラムがすべて同じ値になる＆以前のデータを使う可能性が低い
　案③でGO
◆変更点
テーブル定義
　通知条件テーブルにカラムを追加			記事投稿日 / 記事取得日
　記事付与情報テーブルにカラムを追加		更新後既読フラグ

処理
　IF <<URL>>が重複の場合:
　　　IF <<記事投稿日>>が異なる場合:
　　　　　記事メインテーブルの更新日を更新
　　　　　記事付与情報テーブルの更新後既読フラグを更新
　
-----
002.